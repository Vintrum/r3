{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akhil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import set_seed\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from transformers import DistilBertModel, DistilBertForMaskedLM,DistilBertTokenizer,DistilBertForTokenClassification\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "HF_HUB_DISABLE_IMPLICIT_TOKEN=1\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save entropy and triplets \n",
    "path1=r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the pickle file in read-binary mode\n",
    "with open(r'factkg\\factkg_test.pickle', 'rb') as file:\n",
    "    # Load the object from the file\n",
    "    your_object = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'foundingYear': ['\"2006\"'], 'type': ['Private_company_limited_by_shares'], 'locationCity': ['Warsaw'], \n",
    "        'locationCountry': ['Poland'], 'regionServed': ['Poland'], 'keyPerson': ['Adam_Kuriański', 'Andrzej_Chajec'],\n",
    "        'industry': ['\"Telecommunications\"', 'Telecommunication'], 'service': ['Telecommunication'], 'successor': ['\"Aero 2\"'], \n",
    "        'keyPeople': ['Adam_Kuriański', '\"\\'\\'\\'\"', 'Andrzej_Chajec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"I had heard that Mobyland has a successor!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", device_map = 'auto')\n",
    "model = AutoModel.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", device_map = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_cross_entroy(question, facts):\n",
    "    input_text = \"\"\n",
    "    for fact in facts:\n",
    "        if input_text == \"\":\n",
    "            input_text =  fact\n",
    "        else:\n",
    "            input_text =  input_text  + ', ' + fact \n",
    "    input_text = \"Given fact: \" + input_text + ', ' + question + '\\nAnswer:'\n",
    "    prom_text = input_text\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.encode(question, return_tensors=\"pt\").to(device)\n",
    "        beam0_logits = model(input_ids).logits[:, -1, :].to(device)\n",
    "        question_prob = torch.softmax(beam0_logits, dim=-1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.encode(facts, return_tensors=\"pt\").to(device)\n",
    "        beam0_logits = model(input_ids).logits[:, -1, :].to(device)\n",
    "        fact_prob = torch.softmax(beam0_logits, dim=-1).to(device)\n",
    "    \n",
    "    \n",
    "    ans_h = -(question_prob * torch.log(fact_prob)).sum().to(device)\n",
    "\n",
    "    if len(facts)>3:\n",
    "        ans_h=ans_h/2\n",
    "    return ans_h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_entroy(question, facts):\n",
    "    input_text = \"\"\n",
    "    for fact in facts:\n",
    "        if input_text == \"\":\n",
    "            input_text =  fact\n",
    "        else:\n",
    "            input_text =  input_text  + ', ' + fact \n",
    "    input_text = \"Given fact: \" + input_text + ', ' + question + '\\nAnswer:'\n",
    "    prom_text = input_text\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.encode(prom_text, return_tensors=\"pt\").to(device)\n",
    "        beam0_logits = model(input_ids).logits[:, -1, :].to(device)\n",
    "        beam0_prob = torch.softmax(beam0_logits, dim=-1).to(device)\n",
    "        ans_h = -(beam0_prob * torch.log(beam0_prob)).sum().to(device)\n",
    "    if len(facts)>3:\n",
    "        ans_h=ans_h/2\n",
    "    return ans_h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_cosine_sim(question, facts):\n",
    "    input_text = \"\"\n",
    "    for fact in facts:\n",
    "        if input_text == \"\":\n",
    "            input_text =  fact\n",
    "        else:\n",
    "            input_text =  input_text  + ', ' + fact \n",
    "    input_text = \"Given fact: \" + input_text + ', ' + question + '\\nAnswer:'\n",
    "    prom_text = input_text\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(question, return_tensors=\"pt\")\n",
    "        beam0_logits = model(**input_ids)\n",
    "        question_prob = beam0_logits.last_hidden_state\n",
    "    facts.replace(\"[\",\"\")\n",
    "    facts.replace(\"]\",\"\")\n",
    "    facts.replace(\",\",\" \")\n",
    "    facts.replace(\"'\",\"\")\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(facts, return_tensors=\"pt\")\n",
    "        beam0_logits = model(**input_ids)\n",
    "        fact_prob = beam0_logits.last_hidden_state\n",
    "    \n",
    "    # print(question_prob.shape)\n",
    "    # print(fact_prob.shape)\n",
    "\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "    ans_h =cos(question_prob,fact_prob[:,0:12,:])\n",
    "\n",
    "    return torch.mean(ans_h)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 15, 2048])\n",
      "['Mobyland', 'foundingYear', '2006'] tensor(0.1761)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 18, 2048])\n",
      "['Mobyland', 'type', 'Private_company_limited_by_shares'] tensor(0.1676)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 14, 2048])\n",
      "['Mobyland', 'locationCity', 'Warsaw'] tensor(0.1685)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 14, 2048])\n",
      "['Mobyland', 'locationCountry', 'Poland'] tensor(0.1602)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 15, 2048])\n",
      "['Mobyland', 'regionServed', 'Poland'] tensor(0.1663)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 17, 2048])\n",
      "['Mobyland', 'keyPerson', 'Adam_Kuriański'] tensor(0.1933)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 13, 2048])\n",
      "['Mobyland', 'industry', 'Telecommunications'] tensor(0.1875)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 13, 2048])\n",
      "['Mobyland', 'service', 'Telecommunication'] tensor(0.1750)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 16, 2048])\n",
      "['Mobyland', 'successor', 'Aero 2'] tensor(0.1980)\n",
      "torch.Size([1, 12, 2048])\n",
      "torch.Size([1, 17, 2048])\n",
      "['Mobyland', 'keyPeople', 'Adam_Kuriański'] tensor(0.1938)\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "subgraph=[]\n",
    "ent=[]\n",
    "for relation, object in data.items():\n",
    "                if [str(relation)] not in subgraph:\n",
    "                    subgraph.append([str('Mobyland'),str(relation),str(object[0]).strip(\"\\\"\")])\n",
    "                    ent_temp=ans_cosine_sim(str(query),str(subgraph[0]))\n",
    "                    ent.append(ent_temp)\n",
    "                    print(subgraph[0],ent_temp)\n",
    "                    \n",
    "                    subgraph=[]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 1 2 7 0 6 5 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mobyland', 'foundingYear', '2006'] tensor(2.4138)\n",
      "['Mobyland', 'type', 'Private_company_limited_by_shares'] tensor(2.4057)\n",
      "['Mobyland', 'locationCity', 'Warsaw'] tensor(2.4802)\n",
      "['Mobyland', 'locationCountry', 'Poland'] tensor(2.3519)\n",
      "['Mobyland', 'regionServed', 'Poland'] tensor(2.3324)\n",
      "['Mobyland', 'keyPerson', 'Adam_Kuriański'] tensor(2.4788)\n",
      "['Mobyland', 'industry', 'Telecommunications'] tensor(2.3600)\n",
      "['Mobyland', 'service', 'Telecommunication'] tensor(2.2837)\n",
      "['Mobyland', 'successor', 'Aero 2'] tensor(2.4481)\n",
      "['Mobyland', 'keyPeople', 'Adam_Kuriański'] tensor(2.4872)\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "subgraph=[]\n",
    "for relation, object in data.items():\n",
    "                if [str(relation)] not in subgraph:\n",
    "                    subgraph.append([str('Mobyland'),str(relation),str(object[0]).strip(\"\\\"\")])\n",
    "                    print(subgraph[0],ans_entroy(str(query),str(subgraph[0])))\n",
    "                    subgraph=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('dbpedia_2015_undirected_light.pickle', 'rb') as f:\n",
    "    kg = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "qu = list(dataset.keys())\n",
    "questions_dict={}\n",
    "entity_set_dict = {}\n",
    "label_set_dict = {}\n",
    "q_id=0\n",
    "for line in dataset:\n",
    "    if not line:\n",
    "        continue\n",
    "    questions_dict[q_id]=qu[q_id]    \n",
    "    entity_set_dict[q_id] = dataset[line][\"Entity_set\"]\n",
    "    label_set_dict[q_id] = dataset[line][\"Label\"]\n",
    "    q_id+=1\n",
    "\n",
    "\n",
    "dataset_len=len(questions_dict)\n",
    "a=0\n",
    "k1=4\n",
    "k2=4\n",
    "data_num=range(a,dataset_len+1,1)\n",
    "total_correct=0        \n",
    "        \n",
    "question_id_list=[]\n",
    "question_list=[]\n",
    "entity_set_list=[]\n",
    "ground_truth_list=[]\n",
    "contexts_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ent(question,subgraph,n):\n",
    "    ent=[]\n",
    "    question=(str(question))\n",
    "  \n",
    "    for i in subgraph:\n",
    "        ent.append(([i,ans_entroy(question,i).cpu().item()]))\n",
    "\n",
    "    q=open('ent_2\\\\'+str(n)+'.txt','w',encoding='utf-8')\n",
    "    q.write(str(question)+\"\\n\"+str((ent)))\n",
    "    q.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for ii in tqdm(data_num):\n",
    "    question = questions_dict[ii]\n",
    "    entity_set = entity_set_dict[ii]\n",
    "    ground_truth =label_set_dict[ii]\n",
    "    \n",
    "    # print(question, entity_set, ground_truth)\n",
    "    # I have heard that Mobyland had a successor. ['Mobyland'] [True]\n",
    "    \n",
    "    triplets=[]\n",
    "    cossim=[]\n",
    "    i=0\n",
    "    pos_list=[]\n",
    "    # question_input = tokenizer([question], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    # question_embedding = question_model(**question_input).last_hidden_state.mean(dim=1)\n",
    "    # question_embedding2 = question_model2(**question_input).last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    subgraph = []\n",
    "\n",
    "    for entity in entity_set:\n",
    "        if entity in kg:\n",
    "            \n",
    "     \n",
    "            # {'foundingYear': ['\"2006\"'], 'type': ['Private_company_limited_by_shares'], 'locationCity': ['Warsaw'], \n",
    "            # 'locationCountry': ['Poland'], 'regionServed': ['Poland'], 'keyPerson': ['Adam_Kuriański', 'Andrzej_Chajec'],\n",
    "            # 'industry': ['\"Telecommunications\"', 'Telecommunication'], 'service': ['Telecommunication'], 'successor': ['\"Aero 2\"'], \n",
    "            # 'keyPeople': ['Adam_Kuriański', '\"\\'\\'\\'\"', 'Andrzej_Chajec']}\n",
    "            \n",
    "            for relation, object in kg[entity].items():\n",
    "                if [str(relation)] not in subgraph:\n",
    "                    subgraph.append([str(entity),str(relation),str(object[0]).strip(\"\\\"\")])\n",
    "                \n",
    "            #     m=0\n",
    "            #     # print(kg[entity][relation])\n",
    "            #     # ['\"2006\"']\n",
    "            #     # ['Private_company_limited_by_shares']\n",
    "            #     # ['Warsaw']\n",
    "            #     # ['Poland']\n",
    "            #     # ['Poland']\n",
    "            #     # ['Adam_Kuriański', 'Andrzej_Chajec']\n",
    "            #     # ['\"Telecommunications\"', 'Telecommunication']\n",
    "            #     # ['Telecommunication']\n",
    "            #     # ['\"Aero 2\"']\n",
    "            #     # ['Adam_Kuriański', '\"\\'\\'\\'\"', 'Andrzej_Chajec']\n",
    "                \n",
    "            #     # print(kg[entity][relation])\n",
    "            #     # 2006\n",
    "            calc_ent(question,subgraph,n)\n",
    "            subgraph = []\n",
    "    n+=1\n",
    "            #     for obj in kg[entity][relation]:\n",
    "            #         print(kg[obj].items())\n",
    "            #         break \n",
    "                # break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "files = os.listdir(path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ret1(q):\n",
    "    arr1=[]\n",
    "    arr0=[]\n",
    "\n",
    "    data = ast.literal_eval(q)\n",
    "    for i in data:\n",
    "        arr0.append(i[0])\n",
    "        arr1.append(i[1])\n",
    "    srt=(np.argsort(arr1))\n",
    "    arr=[arr0[i] for i in srt]\n",
    "    return arr[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr_z=[]\n",
    "for i in files:\n",
    "    t1=[]\n",
    "    q=open(path1+\"\\\\\"+i,encoding=\"utf-8\")\n",
    "    print(i)\n",
    "    temp=q.read()\n",
    "    temp=temp.split(\"\\n\")\n",
    "    t2=ret1(temp[1])\n",
    "    arr_z.append([temp[0],t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr_z, columns=['Attributes', 'Value'])\n",
    "df.to_csv('ans_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s2=pd.read_csv(\"ans_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt=\"\"\"Verify the  following claims.\\n The context is the evidence of triplets may help your verifying.\\n\n",
    "#             Each context contains triplets in the form of [head, relation, tail] and it means \"head's relation is tail.\".\n",
    "#             Choose one of {True, False}:\n",
    "#         \"\"\"\n",
    "\n",
    "# prompt+=\"\"\"\n",
    "#         Context 1: [['Ahamad_Kadhim', 'clubs', \"Al-Zawra'a SC\"], ] Claim 1: Ahmad Kadhim Assad's club is Al-Zawra'a SC.\n",
    "#         Answer 1: True, based on the evidence set, Ahmad Kadhim Assad's club is Al-Zawra'a SC.\n",
    "#         Context 2: [['Bananaman', 'firstAired', '\"1983-10-03\"'], ['Bananaman', 'starring', 'Tim_Brooke-Taylor'], ] Claim 2: Yeah! I know that a TV show, which starred Tim Brooke-Taylor, first aired on 3rd October 1983!\n",
    "#         Answer 2: True, the claim is supported by the evidence since Bananaman refers to the TV show.\n",
    "#         Context 3: [['Jamie_Lawrence', 'composer', 'Death_on_a_Factory_Farm'], ['Death_on_a_Factory_Farm', 'director', 'Sarah_Teale'], ] Claim 3: Really? Jamie Lawrence is the music composer of the 83 minute 'Death on a Factory Farm' film, directed by Sarah Teale!\n",
    "#         Answer 3: False, there is no evidence for the 83 minute length.\n",
    "#         Context 4: [[], ] Claim 4: Do you know Milan Hodža? he had a religion.\n",
    "#         Answer 4: False, there is no evidence that Milan had a religion.\n",
    "#         Context 5: [[], ] Claim 5: No, but the leader of the United States is not Olena Serdiuk.\n",
    "#         Answer 5: True, based on the evidence set, there is no information that the leader of the United States is Olena Serdiuk.\n",
    "#         Context 6: [['Brandon_Carter', 'almaMater', 'University_of_Cambridge'], ['Brandon_Carter', 'birthPlace', 'England'], ['University_of_Cambridge', 'viceChancellor', 'Leszek_Borysiewicz'], ] Claim 6: Brandon Carter was born in England and graduated from the University of Cambridge where the current Chancellor is Leszek Borysiewicz.\n",
    "#         Answer 6: True, everything of the claim is supported by the evidence set.\n",
    "#         Context 7: [['Unpublished_Story', 'director', 'Harold_French'], ['Unpublished_Story', 'cinematography', 'Bernard_Knowles'], ] Claim 7: 'A film' was produced by Anatole de Grunwald, directed by Harold French, with cinematography done by Bernard Knowles.\n",
    "#         Answer 7: False, there is no information about the producer of 'Unpublished_Story'.\n",
    "#         Context 8: [['200_Public_Square', 'location', 'Cleveland'], ['200_Public_Square', 'floorCount', '\"45\"'], ['Cleveland', 'country', 'United_States'], ] Claim 8: Yes, with a floor count of 45, 200 Public Square is located in Cleveland in the United States.\n",
    "#         Answer 8: True, everything of the claim is supported by the evidence set.\\n\"\"\"\n",
    "#         #Context 9: [['Bananaman', 'starring', 'Bill_Oddie'], ['Bananaman', 'network', 'Broadcasting_House'], ['Bananaman', 'locationCity', 'Broadcasting_House'], ] Claim 9: Bananaman the TV series starred by a person was shown on the company and the company headquarters is called Broadcasting House.\n",
    "#         #Answer 9: True, everything of the claim is supported by the evidence set.\n",
    "#         #Context 10: [['Azerbaijan', 'leaderName', 'Artur_Rasizade'], [\"Baku_Turkish_Martyrs'_Memorial\", 'designer', '\"Hüseyin Bütüner and Hilmi Güner\"'], [\"Baku_Turkish_Martyrs'_Memorial\", 'location', 'Azerbaijan'], ] Claim 10: The place, designed by Huseyin Butuner and Hilmi Guner, is located in a country, where the leader is Artur Rasizade.\n",
    "#         #Answer 10: True, everything of the claim is supported by the evidence set.\n",
    "#         #Context 11: [['AIDAstella', 'shipBuilder', 'Meyer_Werft'], ['AIDAstella', 'shipOperator', 'AIDA_Cruises'], ] Claim 11: AIDA Cruise line operated the ship which was built by Meyer Werft in Townsend, Poulshot, Wiltshire.\n",
    "#         #Answer 11: False, there is no evidence for Townsend, Poulshot, Wiltshire.\n",
    "#         #Context 12: [[], ] Claim 12: An academic journal with code IJPHDE is also Acta Math. Hungar.\n",
    "#         #Answer 12: False, there is no evidence that the academic journal is also Acta Math. Hungar.\n",
    "\n",
    "\n",
    "# prompt+=\"\"\"Now verify the following claim in the same way of these examples \\n \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"Please verify the statement based on the given evidences from a knowledge graph. \n",
    "\n",
    "# Notes)\n",
    "\n",
    "# 1). If there is any evidence that completely supports the statement, the answer is 'True', otherwise is 'False'.\n",
    "# 2). Be careful for the relations in evidences. For example, 'builder' does not equal to 'owner', 'manager' does not equal to 'leader'.\n",
    "# 3). For questions like 'A has a wife', if there is any evidence that A has a spouse with any name, the answer is 'True'.\n",
    "# 4). When no evidence is provided, you MUST verify the statement and return 'True' or 'False' based on your common sense. NEVER say ANYTHING like 'Please provide more evidences'.\n",
    "# 5). You should provide a brief reason with several words, then tell that the answer is 'True' or 'False'. NEVER say ANYTHING without direct reason like 'Based on the provided evidences, ...', 'Here is my reasoning: ...', etc.\n",
    "\n",
    "# Examples)\n",
    "# \"\"\"\n",
    "# prompt+=\"\"\"\n",
    "#         Context 1: [['Ahamad_Kadhim', 'clubs', \"Al-Zawra'a SC\"], ] Claim 1: Ahmad Kadhim Assad's club is Al-Zawra'a SC.\n",
    "#         Answer 1: True, based on the evidence set, Ahmad Kadhim Assad's club is Al-Zawra'a SC.\n",
    "#         Context 2: [['Bananaman', 'firstAired', '\"1983-10-03\"'], ['Bananaman', 'starring', 'Tim_Brooke-Taylor'], ] Claim 2: Yeah! I know that a TV show, which starred Tim Brooke-Taylor, first aired on 3rd October 1983!\n",
    "#         Answer 2: True, the claim is supported by the evidence since Bananaman refers to the TV show.\n",
    "#         Context 3: [['Jamie_Lawrence', 'composer', 'Death_on_a_Factory_Farm'], ['Death_on_a_Factory_Farm', 'director', 'Sarah_Teale'], ] Claim 3: Really? Jamie Lawrence is the music composer of the 83 minute 'Death on a Factory Farm' film, directed by Sarah Teale!\n",
    "#         Answer 3: False, there is no evidence for the 83 minute length.\n",
    "#         Context 4: [[], ] Claim 4: Do you know Milan Hodža? he had a religion.\n",
    "#         Answer 4: False, there is no evidence that Milan had a religion.\n",
    "        # \"\"\"\n",
    "\n",
    "# prompt+=\"\"\"\n",
    "#     Claim: Ahmad Kadhim Assad's club is Al-Zawra'a SC.\n",
    "#     Answer: True.\n",
    "#     Claim: Yeah! I know that a TV show, which starred Tim Brooke-Taylor, first aired on 3rd October 1983!\n",
    "#     Answer: True.\n",
    "#     Claim: Really? Jamie Lawrence is the music composer of the 83 minute 'Death on a Factory Farm' film, directed by Sarah Teale!\n",
    "#     Answer: False.\n",
    "#     Claim: Do you know Milan Hodža? he had a religion.\n",
    "#     Answer: False.\n",
    "#     Claim: No, but the leader of the United States is not Olena Serdiuk.\n",
    "#     Answer: True.\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# prompt = \"\"\"Please verify the statement based on the given evidences from a knowledge graph. \n",
    "\n",
    "# Notes)\n",
    "\n",
    "# 1). If there is any evidence that completely supports the statement, the answer is 'True', otherwise is 'False'.\n",
    "# 2). For questions like 'A has a wife', if there is any evidence that A has a spouse with any name, the answer is 'True'.\n",
    "# 2). When no evidence is provided, you MUST verify the statement and return 'True' or 'False' based on your common sense. NEVER say ANYTHING like 'Please provide more evidences'.\n",
    "# 4). You should provide a brief reason with several words, then tell that the answer is 'True' or 'False'. NEVER say ANYTHING without direct reason like 'Based on the provided evidences, ...', 'Here is my reasoning: ...', etc.\n",
    "# \"\"\"\n",
    "\n",
    "prompt=\"\"\" verify the following claim \\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,j in zip(s2[\"Attributes\"],s2[\"Value\"]):\n",
    "\n",
    "    temp_prompt=prompt\n",
    "    temp_prompt+=\" Claim: \"+i+'\\n'+'Answer: '\n",
    "    chat = [\n",
    "    {\"role\": \"System\", \"content\": \"You are a helpful assistant that must absolutely return an answer from the set {True, False}.\"},\n",
    "    {\"role\": \"user\", \"content\": temp_prompt},\n",
    "            ]\n",
    "\n",
    "    x[i]=tokenizer.apply_chat_template(chat, tokenize=True,add_generation_prompt=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "for i in x:\n",
    "    q=open('f_ans5\\\\'+str(n)+'.txt','w',encoding='utf-8')\n",
    "    outputs = model.generate(torch.tensor(x[i]).clone().detach().to(device),temperature=0.2,top_p=0.1, max_new_tokens=400)\n",
    "    q.write(str(tokenizer.decode(outputs[0])))\n",
    "    q.close()\n",
    "    print(n)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[]\n",
    "n=0\n",
    "for i in s2['Attributes'][1:]:\n",
    "    if n==0:\n",
    "        n=1\n",
    "    q=open('f_ans4\\\\'+str(n)+'.txt','r',encoding='utf-8')\n",
    "    n+=1\n",
    "    e=q.readlines()\n",
    "    l1.append(e[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "labels=[]\n",
    "ans=[]\n",
    "for i in s2['Attributes'][1:]:\n",
    "    c=(l1[n])\n",
    "    c=c.lower().replace(\"<|eot_id|>\",\"\")\n",
    "    c=''.join(e for e in c if e.isalnum() or e.isspace())\n",
    "    c=c.split()\n",
    "    print(c)\n",
    "    if 'true' in (c):\n",
    "        labels.append(\"True\")\n",
    "        ans.append([i,\"True\"])\n",
    "    elif 'false' in (c):\n",
    "        labels.append(\"False\")  \n",
    "        ans.append([i,\"False\"])\n",
    "  \n",
    "    else:\n",
    "        labels.append(\"Non Answer\")\n",
    "        ans.append([i,\"Non Answer\"])\n",
    "\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "acc=0\n",
    "for i in s2['Attributes'][1:]:\n",
    "    tl=your_object[i][\"Label\"]\n",
    "    print(str(tl[0]))\n",
    "    if str(tl[0])==labels[n]:\n",
    "        acc+=1\n",
    "    n+=1    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
